第十二课选做题第五题

题目：尝试对 MySQL 不同引擎下测试100万订单数据的增删改查性能

统一使用JDBC进行操作

**Insert操作：**

​	不使用连接池， 用普通的获取链接的方式， JDBC代码为：

```java

public class JdbcInsertBatch {
    private static int insert(List<Order> orderList) {
        Connection conn = ConnectionUtils.getConnection();
        String sql = "insert into `order` (payment, payment_type, status, payment_time, consign_time, end_time, close_time, user_id, address_id, create_time, update_time) " +
                "values (?,?,?,?,?,?,?,?,?,?,?)";
        PreparedStatement pstmt = null;
        int count = 0;
        try {
            conn.setAutoCommit(false);
            pstmt = conn.prepareStatement(sql);
            for (Order order : orderList) {
                pstmt.setBigDecimal(1, order.getPayment());
                pstmt.setInt(2, order.getPaymentType());
                pstmt.setInt(3, order.getStatus());
                pstmt.setLong(4, order.getPaymentTime());
                pstmt.setLong(5, order.getConsignTime());
                pstmt.setLong(6, order.getEndTime());
                pstmt.setLong(7, order.getCloseTime());
                pstmt.setLong(8, order.getUserId());
                pstmt.setLong(9, order.getAddressId());
                pstmt.setLong(10, order.getCreateTime());
                pstmt.setLong(11, order.getUpdateTime());
                pstmt.addBatch();
                count++;
                if (count % 10000 == 0) {
                    pstmt.executeBatch();
                }
            }
            pstmt.executeBatch();
            conn.commit();
        } catch (SQLException e) {
            e.printStackTrace();
        } finally {
            ConnectionUtils.closeResource(conn, pstmt);
        }
        return count;
    }

    public static void main(String[] args) {
        List<Order> orderList = new ArrayList<>(1000000);
        BigDecimal payment = new BigDecimal("2.5");

        for (int i = 0; i < 1000000; i++) {
            Long currTimeStamp = System.currentTimeMillis();
            Order order = new Order();
            order.setPayment(payment);
            order.setPaymentType(1);
            order.setStatus(1);
            order.setPaymentTime(currTimeStamp);
            order.setConsignTime(currTimeStamp);
            order.setEndTime(currTimeStamp);
            order.setCloseTime(currTimeStamp);
            order.setCreateTime(currTimeStamp);
            order.setUpdateTime(currTimeStamp);
            order.setUserId(RandomUtil.randomLong(200000));
            order.setAddressId(RandomUtil.randomLong(200000));
            orderList.add(order);
        }

        long before = System.currentTimeMillis();
        int result = insert(orderList);
        long after = System.currentTimeMillis();

        System.out.println("insert result is: " + result);
        System.out.println("cost time is : " + (after - before) + " ms");
    }
}
```

InnoDB引擎用时时间为：13.416s

```
com.xiaowenhou.jdbc.JdbcInsertBatch
insert result is: 1000000
cost time is : 13416 ms

Process finished with exit code 0
```

MyISAM引擎用时时间为：10.634s

```
com.xiaowenhou.jdbc.JdbcInsertBatch
insert result is: 1000000
cost time is : 10634 ms

Process finished with exit code 0
```

Memory引擎用时时间为：9.274S

```
com.xiaowenhou.jdbc.JdbcInsertBatch
insert result is: 1000000
cost time is : 9274 ms

Process finished with exit code 0
```

使用memory时还有点小插曲，mysql5.7中默认内存表的大小为16M，而memory表是内存表， 因此插入时报表已经满了的错误， 解决方式是修改my.ini(my.inf)配置文件， 将max_heap_table_size参数调大， 我调到了1G大小， 插入成功。

由此可见， **插入效率， innodb， myisam， memory依次降低**， 分析应该是因为innodb支持事务， 额外的事务操作消耗了一定的性能， 此外， memory引擎是基于内存的， 不需要落盘， 因此效率最高。



**Delete操作：** 代码如下， **随机删除80w条数据**

```java
package com.xiaowenhou.jdbc;

import cn.hutool.core.util.RandomUtil;
import com.xiaowenhou.bean.Order;

import java.math.BigDecimal;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.SQLException;
import java.util.ArrayList;
import java.util.List;

public class JdbcDeleteBatch {

    private static int delete(List<Long> idList) {
        Connection conn = ConnectionUtils.getConnection();
        String sql = "delete from `order` where id= ?";
        PreparedStatement pstmt = null;
        int count = 0;
        try {
            conn.setAutoCommit(false);
            pstmt = conn.prepareStatement(sql);
            for (Long id : idList) {
                pstmt.setLong(1, id);
                pstmt.addBatch();
                count++;
                if (count % 10000 == 0) {
                    pstmt.executeBatch();
                }
            }
            pstmt.executeBatch();
            conn.commit();
        } catch (SQLException e) {
            e.printStackTrace();
        } finally {
            ConnectionUtils.closeResource(conn, pstmt);
        }
        return count;
    }

    public static void main(String[] args) {
        List<Long> idList = new ArrayList<>();
        for (int i = 0; i < 800000; i++) {
            idList.add(RandomUtil.randomLong(1, 1000000));
        }

        long before = System.currentTimeMillis();
        int result = delete(idList);
        long after = System.currentTimeMillis();

        System.out.println("delete result is: " + result);
        System.out.println("cost time is : " + (after - before) + " ms");
    }
}
```

InnoDB引擎用时：39.380s

```
com.xiaowenhou.jdbc.JdbcDeleteBatch
delete result is: 800000
cost time is : 39380 ms

Process finished with exit code 0
```

MyISAM引擎用时：67.723s

```
com.xiaowenhou.jdbc.JdbcDeleteBatch
delete result is: 800000
cost time is : 67723 ms

Process finished with exit code 0
```

Memory引擎用时：

```
com.xiaowenhou.jdbc.JdbcDeleteBatch
delete result is: 800000
cost time is : 25189 ms

Process finished with exit code 0
```

随机删除时， **效率为MyISam， InnoDb， Memory依次降低**。MyIsam效率较低分析应该是因为MyIsam引擎的表，索引分开存储， 根据主键ID删除数据时， 还要再找到数据对应的位置进行删除， 而Innodb主键和数据在一起， 避免了再去寻找数据的操作。

**Update操作**：代码如下， **随机更新80w条数据**

```java
public class JdbcUpdateBatch {
    private static int update(List<Order> orderList) {
        Connection conn = ConnectionUtils.getConnection();
        String sql = "update `order` set payment= ? where id= ?";
        PreparedStatement pstmt = null;
        int count = 0;
        try {
            conn.setAutoCommit(false);
            pstmt = conn.prepareStatement(sql);
            for (Order order : orderList) {
                pstmt.setBigDecimal(1, order.getPayment());
                pstmt.setLong(2, order.getId());
                pstmt.addBatch();
                count++;
                if (count % 100000 == 0) {
                    pstmt.executeBatch();
                }
            }
            pstmt.executeBatch();
            conn.commit();
        } catch (SQLException e) {
            e.printStackTrace();
        } finally {
            ConnectionUtils.closeResource(conn, pstmt);
        }
        return count;
    }

    public static void main(String[] args) {
        List<Order> orderList = new ArrayList<>(1000000);
        BigDecimal payment = new BigDecimal("50.55");

        for (int i = 0; i < 800000; i++) {
            Order order = new Order();
            order.setPayment(payment);
            order.setId(RandomUtil.randomLong(1, 1000000));
            orderList.add(order);
        }

        long before = System.currentTimeMillis();
        int result = update(orderList);
        long after = System.currentTimeMillis();

        System.out.println("update result is: " + result);
        System.out.println("cost time is : " + (after - before) + " ms");
    }
}
```

InnoDB引擎：用时40.872s

```
com.xiaowenhou.jdbc.JdbcUpdateBatch
update result is: 800000
cost time is : 40872 ms

Process finished with exit code 0
```

MyISAM引擎用时：54.707s

```
com.xiaowenhou.jdbc.JdbcUpdateBatch
update result is: 800000
cost time is : 54707 ms

Process finished with exit code 0
```

Memory引擎用时：27.602s

```
com.xiaowenhou.jdbc.JdbcUpdateBatch
update result is: 800000
cost time is : 27602 ms

Process finished with exit code 0
```

**随机更新时，** **效率依然为MyISam， InnoDb， Memory依次降低**。

**Select操作**， 代码如下： **随机查询80w条数据**

```java
public class JdbcSelectBatch {
    private static int select(List<Long> idList) {
        Connection conn = ConnectionUtils.getConnection();
        String sql = "select * from `order` where id = ?";
        PreparedStatement pstmt = null;
        int count = 0;
        try {
            conn.setAutoCommit(false);
            pstmt = conn.prepareStatement(sql);
            for (Long id : idList) {
                pstmt.setLong(1, id);
                pstmt.addBatch();
                count++;
                if (count % 100000 == 0) {
                    pstmt.executeBatch();
                }
            }
            pstmt.executeBatch();
            conn.commit();
        } catch (SQLException e) {
            e.printStackTrace();
        } finally {
            ConnectionUtils.closeResource(conn, pstmt);
        }
        return count;
    }

    public static void main(String[] args) {
        List<Long> idList = new ArrayList<>(800000);
        for (int i = 0; i < 800000; i++) {
            idList.add(RandomUtil.randomLong(1, 1000000));
        }

        long before = System.currentTimeMillis();
        int result = select(idList);
        long after = System.currentTimeMillis();

        System.out.println("select result is: " + result);
        System.out.println("cost time is : " + (after - before) + " ms");
    }
}
```

InnoDB引擎：用时34.612s

```java
com.xiaowenhou.jdbc.JdbcSelectBatch
select result is: 800000
cost time is : 34612 ms

Process finished with exit code 0
```

MyISAM引擎用时：44.910s

```
com.xiaowenhou.jdbc.JdbcSelectBatch
select result is: 800000
cost time is : 44910 ms

Process finished with exit code 0

```

Memory引擎用时：28.589s

```
com.xiaowenhou.jdbc.JdbcSelectBatch
select result is: 800000
cost time is : 28589 ms

Process finished with exit code 0
```

**随机查询时，** **效率依然为MyISam， InnoDb， Memory依次降低**。

根据id批量查询测试：

InnoDB引擎用时2.518s

​	![image-20210228134943508](C:\Users\xiaowenhou\AppData\Roaming\Typora\typora-user-images\image-20210228134943508.png)

MyISAM引擎用时：2.502s

![image-20210228135137685](C:\Users\xiaowenhou\AppData\Roaming\Typora\typora-user-images\image-20210228135137685.png)

Memory引擎用时：2.537s

![image-20210228135946667](C:\Users\xiaowenhou\AppData\Roaming\Typora\typora-user-images\image-20210228135946667.png)

经过多次测试， 根据主键ID批量查询时三种引擎的效率相差不大， 性能主要消耗在大数据量的传输上