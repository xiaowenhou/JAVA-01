**第十三节课作业选做题第三题**

题目：按自己设计的表结构，插入1000万订单模拟数据，测试不同方式的插入效率

**通过JDBC代码插入数据， 效率和插入100万数据类似， 不同方式的插入时间基本都是插入100万数据的十倍， 因此，还是使用多线程批量处理， 手动提交事务，并且使用连接池的方式效率最高， 插入1000万数据用时不到60s；如果不适用多线程， 仅仅使用批量提交的方式， 插入1000w条数据需要130s左右。**

以下为多线程插入1000w条数据的耗时

```
com.xiaowenhou.test100w.JdbcInsertWithPerparedAndHikariConcurrency
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
cost time is : 56191 ms

Process finished with exit code 0
```

​	

测试其他的导入方式：

**1、使用mysqldump导出， source导入**

​		 **导出：**

```
	 mysqldump -uroot -p -q -e -t home_work order > C:\Users\xiaowenhou\Desktop\order\order.sql

			表示将home_work数据库下的order表导入到order.sql的sql文件中
			-q   表示mysql从服务器查询取得记录后直接输出， 而不是取得记录后先存到缓存中
			-e   表示使用具有多个VALUES列的INSERT语法。这样使导出文件更小，并加速导入时的速度。
			-t    表示仅导出表数据， 不导出表结构
```

​		使用该命令， 导出1000w数据的表， **用时15s**

​		**导入：**

```
	use 数据库名;
	source C:\Users\xiaowenhou\Desktop\order\ordeer.sql
```

​		使用该命令， 导入1000w数据， **用时120s**

**2、使用select * into outfile...导出， 使用load data infile...导入**

​		**导出：**			

```
select * into outfile 'order.txt' fields terminated by ',' from `order`;
```

​		使用该命令， 导出1000w数据， **用时11.899s**

​		使用该命令， 有可能会遇到以下错误

```
ERROR 1290 (HY000): The MySQL server is running with the --secure-file-priv option so it cannot execute this statement
```

​		解决方式是修改my.ini或者my.inf文件， 将secure-file-priv参数修改为‘’即可。

​	**导入：**

```
load data infile 'order.txt' into table `order`  fields terminated by ',';
```

​		使用该命令， 导入1000w条数据， **用时84.558s**

**3、使用create table t2 as select * from table的方式**

```
CREATE TABLE order_dump AS SELECT * FROM `order`;
```

​	使用该命令， 导入1000w条数据到另一张表， **用时47.723s**



**结论：如果是创建数据并且进行插入， 使用多线程并行， 并且开启批量处理和手动事务提交的效率最高；如果是将已经存在的表中的数据导入到另一张表中时， 通过创建并导入的方式导入数据速度最快， 导入1000w条数据仅需要48s；其次使用mysql的load data命令的效率也比较高。** 